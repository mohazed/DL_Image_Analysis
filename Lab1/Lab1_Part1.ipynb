{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a705d20",
      "metadata": {
        "id": "7a705d20"
      },
      "source": [
        "# Lab1 ‚Äî PyTorch Foundations for Computer Vision\n",
        "\n",
        "**Course**: Deep Learning for Image Analysis\n",
        "\n",
        "**Class**: M2 IASD App  \n",
        "\n",
        "**Professor**: Mehyar MLAWEH\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "- Understand how **neurons and layers** are implemented in PyTorch\n",
        "- Manipulate **tensors** and reason about shapes\n",
        "- Use **autograd** to compute gradients\n",
        "- Implement a **training loop** yourself\n",
        "- Connect theory (neurons, loss, backprop) to actual code\n",
        "\n",
        "‚ö†Ô∏è This notebook is **intentionally incomplete**.  \n",
        "Whenever you see **`# TODO`**, you are expected to write code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07470cd",
      "metadata": {
        "id": "e07470cd"
      },
      "source": [
        "\n",
        "**Deadline:** üóìÔ∏è **Saturday, February 7th (23:59)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60119f3a",
      "metadata": {
        "id": "60119f3a"
      },
      "source": [
        "## ü§ñ A small (honest) note before you start\n",
        "\n",
        "Let‚Äôs be real for a second.\n",
        "\n",
        " I know you **can use LLMs (ChatGPT, Copilot, Claude, etc.)** to help you with this lab.  \n",
        "And yes, **I use them too**, so don‚Äôt worry üòÑ\n",
        "\n",
        "üëâ **You are allowed to use AI tools.**  \n",
        "But here‚Äôs the deal:\n",
        "\n",
        "- Don‚Äôt just **copy‚Äìpaste** code you don‚Äôt understand  \n",
        "- Take time to **read, question, and modify** what the model gives you  \n",
        "- If you can solve a block **by yourself, without AI**, that‚Äôs excellent\n",
        "\n",
        "Remember:\n",
        "\n",
        "> AI can write code for you, but **only you can understand it** ‚Äî and understanding is what matters for exams, projects, and real work.\n",
        "\n",
        "Use these tools **as assistants, not as replacements for thinking**.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Useful documentation (highly recommended)\n",
        "\n",
        "You will often find answers faster (and more reliably) by checking the official documentation:\n",
        "\n",
        "- **PyTorch main documentation**  \n",
        "  https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "- **PyTorch tensors**  \n",
        "  https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "- **Neural network modules (`torch.nn`)**  \n",
        "  https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "- **Loss functions** (`BCEWithLogitsLoss`, CrossEntropy, etc.)  \n",
        "  https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "- **Optimizers** (`SGD`, `Adam`, ‚Ä¶)  \n",
        "  https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "If you learn how to **navigate the documentation**, you are already thinking like a real AI engineer üëå\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f278eff5",
      "metadata": {
        "id": "f278eff5"
      },
      "source": [
        "## PART I"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de614322",
      "metadata": {
        "id": "de614322"
      },
      "source": [
        "## 0) Colab setup ‚Äî GPU check\n",
        "\n",
        "**Instructions**\n",
        "1. In Colab: `Runtime ‚Üí Change runtime type to GPU T4`\n",
        "2. Select **GPU**\n",
        "3. Save and restart runtime\n",
        "\n",
        "Then run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "72e3ba23",
      "metadata": {
        "id": "72e3ba23",
        "outputId": "28651b99-6cff-4a97-bb67-b1db5783b3de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# TODO: set the device correctly (cuda if available, else cpu)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc7ceb1",
      "metadata": {
        "id": "fcc7ceb1"
      },
      "source": [
        "## 1) Imports and reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d0ce2798",
      "metadata": {
        "id": "d0ce2798",
        "outputId": "722a9867-b845-441d-a60c-8ebb9e622e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a874f7311d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# TODO: fix the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9349f5a5",
      "metadata": {
        "id": "9349f5a5"
      },
      "source": [
        "## 2) PyTorch tensors and shapes\n",
        "\n",
        "Tensors are multi-dimensional arrays that support:\n",
        "- GPU acceleration\n",
        "- automatic differentiation\n",
        "\n",
        "Understanding **shapes** is critical in deep learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2998b3f",
      "metadata": {
        "id": "d2998b3f",
        "outputId": "ed1f6605-9345-4316-b050-579eaf884f7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a shape: torch.Size([3])\n",
            "b shape: torch.Size([4, 5])\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055, -0.7581],\n",
            "        [ 1.0783,  0.8008,  1.6806,  0.3559, -0.6866],\n",
            "        [-0.4934,  0.2415, -0.2316,  0.0418, -0.2516],\n",
            "        [ 0.8599, -0.3097, -0.3957,  0.8034, -0.6216]])\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "print(\"a shape:\", a.shape)\n",
        "print(\"b shape:\", b.shape)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d675977",
      "metadata": {
        "id": "0d675977"
      },
      "source": [
        "### üîç Question (answer inside the markdown)\n",
        "- How many dimensions does tensor `b` have?\n",
        "- What does each dimension represent conceptually?\n",
        "\n",
        "* there are 2 dimensions in tensor `b`\n",
        "* in a mathematical understanding it depresents a matrix so the first corresponds to the number of rows and the second to the columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea0588f",
      "metadata": {
        "id": "9ea0588f"
      },
      "source": [
        "### ‚úÖTensor operations\n",
        "\n",
        "Complete the following:\n",
        "\n",
        "1. Create a tensor `x` of shape `(8, 3)` with random values  \n",
        "2. Compute:\n",
        "   - the **mean of each column**\n",
        "   - the **L2 norm of each row**\n",
        "3. Normalize `x` **row-wise** using the L2 norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b4629e99",
      "metadata": {
        "id": "b4629e99"
      },
      "outputs": [],
      "source": [
        "# TODO: create x\n",
        "x = torch.randn(8, 3)\n",
        "\n",
        "# TODO: column mean\n",
        "col_mean = torch.mean(x, dim = 0)\n",
        "\n",
        "\n",
        "# TODO: row-wise L2 norm\n",
        "row_norm = torch.norm(x, dim = 1)\n",
        "\n",
        "\n",
        "\n",
        "# print(x.shape, col_mean.shape, row_norm.shape, x_normalized.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: normalized tensor\n",
        "x_normalized = x / row_norm.view(-1, 1)"
      ],
      "metadata": {
        "id": "_eu_pt8Y58XX"
      },
      "id": "_eu_pt8Y58XX",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4d0f8928",
      "metadata": {
        "id": "4d0f8928"
      },
      "source": [
        "## 3) Artificial neuron ‚Äî from math to code\n",
        "\n",
        "A neuron computes:\n",
        "\n",
        "$$\n",
        "z = \\sum_i w_i x_i + b\n",
        "$$\n",
        "\n",
        "Then applies an activation function:\n",
        "\n",
        "$$\n",
        "y = g(z)\n",
        "$$\n",
        "\n",
        "This section connects directly to the theory seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6d271c97",
      "metadata": {
        "id": "6d271c97",
        "outputId": "cd56516c-079f-4bce-c1cd-10ec77a340e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x = torch.tensor([1.0, -2.0, 3.0])\n",
        "w = torch.tensor([0.2, 0.4, -0.1])\n",
        "b = torch.tensor(0.1)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2d7490",
      "metadata": {
        "id": "db2d7490"
      },
      "source": [
        "### Activation functions\n",
        "\n",
        "1. Implement **ReLU**\n",
        "2. Implement **Sigmoid**\n",
        "3. Apply both to `z` and compare the outputs\n",
        "\n",
        "Which activation preserves negative values?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f307df40",
      "metadata": {
        "id": "f307df40",
        "outputId": "f154132b-4109-4150-a7cf-61f42ba29e50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0., grad_fn=<MaximumBackward0>),\n",
              " tensor(0.3318, grad_fn=<SigmoidBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# TODO\n",
        "def relu(z):\n",
        "  return torch.maximum(z,torch.zeros_like(z))\n",
        "\n",
        "def sigmoid(z):\n",
        "    return torch.sigmoid(z)\n",
        "\n",
        "y_relu = relu(z)\n",
        "y_sigmoid = sigmoid(z)\n",
        "y_relu, y_sigmoid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e764019",
      "metadata": {
        "id": "8e764019"
      },
      "source": [
        "## 4) Autograd and gradients\n",
        "\n",
        "PyTorch uses **automatic differentiation** to compute gradients\n",
        "using the **chain rule** (backpropagation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "50f1aab4",
      "metadata": {
        "id": "50f1aab4",
        "outputId": "fb30f78c-c091-4ec8-db30-f078e89f7fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.890000104904175\n",
            "grad w: tensor([-3.4000, -6.8000,  3.4000])\n",
            "grad b: tensor(-3.4000)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, -1.0], requires_grad=True)\n",
        "w = torch.tensor([0.5, -0.3, 0.8], requires_grad=True)\n",
        "b = torch.tensor(0.2, requires_grad=True)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "loss = (z - 1.0) ** 2\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"loss:\", loss.item())\n",
        "print(\"grad w:\", w.grad)\n",
        "print(\"grad b:\", b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2c78a9",
      "metadata": {
        "id": "fe2c78a9"
      },
      "source": [
        "### üîç Conceptual question\n",
        "\n",
        "- If `b.grad > 0`, should `b` increase or decrease after a gradient descent step?\n",
        "Explain **why** in one sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5bdee3e",
      "metadata": {
        "id": "b5bdee3e"
      },
      "source": [
        "## 5) Toy classification dataset\n",
        "\n",
        "We create a **linearly separable** dataset.\n",
        "\n",
        "Label rule:\n",
        "- class = 1 if `x‚ÇÅ + x‚ÇÇ + x‚ÇÉ > 0`\n",
        "- else class = 0\n",
        "\n",
        "This mimics a very simple classification problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "15c8bc6a",
      "metadata": {
        "id": "15c8bc6a"
      },
      "outputs": [],
      "source": [
        "# TODO: generate a dataset of size N=500 with 3 features\n",
        "X = torch.randn(500, 3)\n",
        "y = torch.randn(500, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(500):\n",
        "  if X[i, 0] + X[i, 1] + X[i, 2] > 0 :\n",
        "    y[i] = 1\n",
        "  else :\n",
        "    y[i] = 0"
      ],
      "metadata": {
        "id": "32bnwrMTDir1"
      },
      "id": "32bnwrMTDir1",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: split into train (80%) and validation (20%)\n",
        "\n",
        "X_train, X_val = X[:400], X[400:]\n",
        "y_train, y_val = y[:400], y[400:]\n"
      ],
      "metadata": {
        "id": "A5OfhLUMEIvi"
      },
      "id": "A5OfhLUMEIvi",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "cgteucc8EfIV",
        "outputId": "d30fdbba-e9fc-49f5-a28c-e1d0a99e4f35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cgteucc8EfIV",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([400, 3]),\n",
              " torch.Size([100, 3]),\n",
              " torch.Size([400, 1]),\n",
              " torch.Size([100, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c16fc2",
      "metadata": {
        "id": "79c16fc2"
      },
      "source": [
        "## 6) Model definition\n",
        "\n",
        "We define a small **MLP** (fully-connected network):\n",
        "\n",
        "`3 ‚Üí 16 ‚Üí 8 ‚Üí 1`\n",
        "\n",
        "Activation: ReLU  \n",
        "Output: raw logits (no sigmoid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d7b69f8d",
      "metadata": {
        "id": "d7b69f8d"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(3, 16),       # TODO: Linear 3 ‚Üí 16\n",
        "            nn.ReLU(),              # TODO: ReLU\n",
        "            nn.Linear(16, 8),       # TODO: Linear 16 ‚Üí 8\n",
        "            nn.ReLU(),              # TODO: ReLU\n",
        "            nn.Linear(8, 1),       # TODO: Linear 8 ‚Üí 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# TODO: create model and move it to the GPU\n",
        "model = MLP().to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c13b2d2",
      "metadata": {
        "id": "9c13b2d2"
      },
      "source": [
        "###  parameters\n",
        "\n",
        "1. Compute **by hand** the total number of parameters\n",
        "2. Verify your answer using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6168e4a5",
      "metadata": {
        "id": "6168e4a5",
        "outputId": "f6822a62-1df3-4f9a-d626-0f89ebc7962a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated by hand: 209\n",
            "Counted by PyTorch: 209\n"
          ]
        }
      ],
      "source": [
        "# TODO: count parameters with PyTorch\n",
        "total_params_calculated = 3*16 + 16 + 16*8 + 8 + 8*1 + 1\n",
        "\n",
        "# Programmatic verification:\n",
        "total_params_pytorch = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"Calculated by hand: {total_params_calculated}\")\n",
        "print(f\"Counted by PyTorch: {total_params_pytorch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f204fb",
      "metadata": {
        "id": "19f204fb"
      },
      "source": [
        "## 7) Training loop\n",
        "\n",
        "You must complete the full training loop:\n",
        "- forward pass\n",
        "- loss computation\n",
        "- backward pass\n",
        "- optimizer step\n",
        "\n",
        "Loss: `BCEWithLogitsLoss`\n",
        "Optimizer: `SGD`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d80ad2c9",
      "metadata": {
        "id": "d80ad2c9",
        "outputId": "fa16a88f-60c5-4690-a883-bb4a0f3afed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | loss = 0.6936067938804626\n",
            "Epoch 5 | loss = 0.6922205686569214\n",
            "Epoch 10 | loss = 0.6908179521560669\n",
            "Epoch 15 | loss = 0.6892109513282776\n"
          ]
        }
      ],
      "source": [
        "# TODO: move data to device\n",
        "X_train_d = X_train.to(device)\n",
        "y_train_d = y_train.to(device)\n",
        "X_val_d = X_val.to(device)\n",
        "y_val_d = y_val.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # TODO: forward\n",
        "    logits = model(X_train_d)\n",
        "\n",
        "    # TODO: loss\n",
        "    loss = criterion(logits, y_train_d)\n",
        "\n",
        "    # TODO: backward\n",
        "    loss.backward()\n",
        "\n",
        "    # TODO: update\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch\", epoch, \"| loss =\", float(loss))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c894744",
      "metadata": {
        "id": "5c894744"
      },
      "source": [
        "## 8) Evaluation\n",
        "\n",
        "1. Apply `sigmoid` to the logits\n",
        "2. Convert probabilities to predictions\n",
        "3. Compute **accuracy** on the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b10b706c",
      "metadata": {
        "id": "b10b706c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e4c96e-64a2-41ac-9efe-6a04fbeae262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 60.00%\n"
          ]
        }
      ],
      "source": [
        "# TODO: evaluation\n",
        "model.eval() # Set model to evaluation mode (disables dropout, etc.)\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for efficiency\n",
        "    # 1. Forward pass on validation data\n",
        "    logits_val = model(X_val_d)\n",
        "\n",
        "    # 2. Apply sigmoid to get probabilities\n",
        "    probs_val = torch.sigmoid(logits_val)\n",
        "\n",
        "    # 3. Convert to predictions (0 or 1) using 0.5 threshold\n",
        "    preds_val = (probs_val > 0.5).float()\n",
        "\n",
        "    # 4. Compute accuracy\n",
        "    # Check where prediction equals target, convert boolean to float, take mean\n",
        "    accuracy = (preds_val == y_val_d).float().mean()\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy.item() * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9698541c",
      "metadata": {
        "id": "9698541c"
      },
      "source": [
        "## 9) Reflection questions (answer inside the markdown)\n",
        "\n",
        "1. Why do we **not** apply sigmoid inside the model?\n",
        "2. What would happen if we removed all ReLU activations?\n",
        "3. How does this toy problem relate to image classification?\n",
        "\n",
        "Write short answers (2‚Äì3 lines each).\n",
        "\n",
        "1 - We use BCEWithLogitsLoss, which combines the Sigmoid layer and the BCELoss in one single class. This is more numerically stable (prevents overflow/underflow issues) than applying them separately.\n",
        "\n",
        "2 - The model would collapse into a single linear transformation (essentially Logistic Regression), regardless of how many layers you add. Without non-linearities, a deep neural network cannot learn complex, non-linear decision boundaries.\n",
        "\n",
        "3 - The fundamental pipeline is identical: Input -> Layers (Weights) -> Non-Linearity -> Loss -> Backprop. In image classification, the input is just a larger tensor (pixels) and we typically use Convolutional layers instead of just Linear layers, but the training logic remains the same."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9f2ed3",
      "metadata": {
        "id": "be9f2ed3"
      },
      "source": [
        "## 10) Bridge to Computer Vision\n",
        "\n",
        "So far:\n",
        "- inputs = vectors of size 3\n",
        "- layers = fully-connected\n",
        "\n",
        "Next session:\n",
        "- inputs = images `(B, C, H, W)`\n",
        "- layers = convolutions\n",
        "- same training logic\n",
        "\n",
        "üëâ **Architecture changes, learning principles stay the same.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f479aad6",
      "metadata": {
        "id": "f479aad6"
      },
      "source": [
        "## Part II ‚Äî Training on MNIST\n",
        "\n",
        "Check the next notebook\n",
        "\n",
        "okay\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}