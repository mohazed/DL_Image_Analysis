{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a705d20",
      "metadata": {
        "id": "7a705d20"
      },
      "source": [
        "# Lab1 â€” PyTorch Foundations for Computer Vision\n",
        "\n",
        "**Course**: Deep Learning for Image Analysis\n",
        "\n",
        "**Class**: M2 IASD App  \n",
        "\n",
        "**Professor**: Mehyar MLAWEH\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "- Understand how **neurons and layers** are implemented in PyTorch\n",
        "- Manipulate **tensors** and reason about shapes\n",
        "- Use **autograd** to compute gradients\n",
        "- Implement a **training loop** yourself\n",
        "- Connect theory (neurons, loss, backprop) to actual code\n",
        "\n",
        "âš ï¸ This notebook is **intentionally incomplete**.  \n",
        "Whenever you see **`# TODO`**, you are expected to write code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07470cd",
      "metadata": {
        "id": "e07470cd"
      },
      "source": [
        "\n",
        "**Deadline:** ðŸ—“ï¸ **Saturday, February 7th (23:59)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60119f3a",
      "metadata": {
        "id": "60119f3a"
      },
      "source": [
        "## ðŸ¤– A small (honest) note before you start\n",
        "\n",
        "Letâ€™s be real for a second.\n",
        "\n",
        " I know you **can use LLMs (ChatGPT, Copilot, Claude, etc.)** to help you with this lab.  \n",
        "And yes, **I use them too**, so donâ€™t worry ðŸ˜„\n",
        "\n",
        "ðŸ‘‰ **You are allowed to use AI tools.**  \n",
        "But hereâ€™s the deal:\n",
        "\n",
        "- Donâ€™t just **copyâ€“paste** code you donâ€™t understand  \n",
        "- Take time to **read, question, and modify** what the model gives you  \n",
        "- If you can solve a block **by yourself, without AI**, thatâ€™s excellent\n",
        "\n",
        "Remember:\n",
        "\n",
        "> AI can write code for you, but **only you can understand it** â€” and understanding is what matters for exams, projects, and real work.\n",
        "\n",
        "Use these tools **as assistants, not as replacements for thinking**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š Useful documentation (highly recommended)\n",
        "\n",
        "You will often find answers faster (and more reliably) by checking the official documentation:\n",
        "\n",
        "- **PyTorch main documentation**  \n",
        "  https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "- **PyTorch tensors**  \n",
        "  https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "- **Neural network modules (`torch.nn`)**  \n",
        "  https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "- **Loss functions** (`BCEWithLogitsLoss`, CrossEntropy, etc.)  \n",
        "  https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "- **Optimizers** (`SGD`, `Adam`, â€¦)  \n",
        "  https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "If you learn how to **navigate the documentation**, you are already thinking like a real AI engineer ðŸ‘Œ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f278eff5",
      "metadata": {
        "id": "f278eff5"
      },
      "source": [
        "## PART I"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de614322",
      "metadata": {
        "id": "de614322"
      },
      "source": [
        "## 0) Colab setup â€” GPU check\n",
        "\n",
        "**Instructions**\n",
        "1. In Colab: `Runtime â†’ Change runtime type to GPU T4`\n",
        "2. Select **GPU**\n",
        "3. Save and restart runtime\n",
        "\n",
        "Then run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "72e3ba23",
      "metadata": {
        "id": "72e3ba23",
        "outputId": "da779f1b-4da0-483c-b466-e14b5de0acbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# TODO: set the device correctly (cuda if available, else cpu)\n",
        "# device = ...\n",
        "\n",
        "# Source - https://stackoverflow.com/a/63302819\n",
        "# Posted by honk\n",
        "# Retrieved 2026-02-02, License - CC BY-SA 4.0\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc7ceb1",
      "metadata": {
        "id": "fcc7ceb1"
      },
      "source": [
        "## 1) Imports and reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0ce2798",
      "metadata": {
        "id": "d0ce2798",
        "outputId": "eba6d3d6-feac-4f28-f92b-f72ce1a42868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cc153f685d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# TODO: fix the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9349f5a5",
      "metadata": {
        "id": "9349f5a5"
      },
      "source": [
        "## 2) PyTorch tensors and shapes\n",
        "\n",
        "Tensors are multi-dimensional arrays that support:\n",
        "- GPU acceleration\n",
        "- automatic differentiation\n",
        "\n",
        "Understanding **shapes** is critical in deep learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2998b3f",
      "metadata": {
        "id": "d2998b3f",
        "outputId": "ff81dbc6-9c4d-4f72-e337-c3eb557e81f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a shape: torch.Size([3])\n",
            "b shape: torch.Size([4, 5])\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055, -0.7581],\n",
            "        [ 1.0783,  0.8008,  1.6806,  0.3559, -0.6866],\n",
            "        [-0.4934,  0.2415, -0.2316,  0.0418, -0.2516],\n",
            "        [ 0.8599, -0.3097, -0.3957,  0.8034, -0.6216]])\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "print(\"a shape:\", a.shape)\n",
        "print(\"b shape:\", b.shape)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d675977",
      "metadata": {
        "id": "0d675977"
      },
      "source": [
        "### ðŸ” Question (answer inside the markdown)\n",
        "- How many dimensions does tensor `b` have?\n",
        "- What does each dimension represent conceptually?\n",
        "\n",
        "* there are 2 dimensions in tensor `b`\n",
        "* in a mathematical understanding it depresents a matrix so the first corresponds to the number of rows and the second to the columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea0588f",
      "metadata": {
        "id": "9ea0588f"
      },
      "source": [
        "### âœ…Tensor operations\n",
        "\n",
        "Complete the following:\n",
        "\n",
        "1. Create a tensor `x` of shape `(8, 3)` with random values  \n",
        "2. Compute:\n",
        "   - the **mean of each column**\n",
        "   - the **L2 norm of each row**\n",
        "3. Normalize `x` **row-wise** using the L2 norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b4629e99",
      "metadata": {
        "id": "b4629e99"
      },
      "outputs": [],
      "source": [
        "# TODO: create x\n",
        "x = torch.randn(8, 3)\n",
        "\n",
        "# TODO: column mean\n",
        "col_mean = torch.mean(x, dim = 0)\n",
        "\n",
        "\n",
        "# TODO: row-wise L2 norm\n",
        "row_norm = torch.norm(x, dim = 1)\n",
        "\n",
        "\n",
        "\n",
        "# print(x.shape, col_mean.shape, row_norm.shape, x_normalized.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: normalized tensor\n",
        "x_normalized = x / row_norm.view(-1, 1)"
      ],
      "metadata": {
        "id": "_eu_pt8Y58XX"
      },
      "id": "_eu_pt8Y58XX",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4d0f8928",
      "metadata": {
        "id": "4d0f8928"
      },
      "source": [
        "## 3) Artificial neuron â€” from math to code\n",
        "\n",
        "A neuron computes:\n",
        "\n",
        "$$\n",
        "z = \\sum_i w_i x_i + b\n",
        "$$\n",
        "\n",
        "Then applies an activation function:\n",
        "\n",
        "$$\n",
        "y = g(z)\n",
        "$$\n",
        "\n",
        "This section connects directly to the theory seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6d271c97",
      "metadata": {
        "id": "6d271c97",
        "outputId": "633c2037-311e-4065-ecd2-d22c37f71bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x = torch.tensor([1.0, -2.0, 3.0])\n",
        "w = torch.tensor([0.2, 0.4, -0.1])\n",
        "b = torch.tensor(0.1)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2d7490",
      "metadata": {
        "id": "db2d7490"
      },
      "source": [
        "### Activation functions\n",
        "\n",
        "1. Implement **ReLU**\n",
        "2. Implement **Sigmoid**\n",
        "3. Apply both to `z` and compare the outputs\n",
        "\n",
        "Which activation preserves negative values?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f307df40",
      "metadata": {
        "id": "f307df40",
        "outputId": "fda6750c-aa3f-484b-f106-8565bcecdfc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 0., 3.]), tensor(0.3100))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# TODO\n",
        "def relu(z):\n",
        "  return torch.maximum(x,torch.zeros_like(x))\n",
        "\n",
        "def sigmoid(z):\n",
        "    return torch.sigmoid(z)\n",
        "\n",
        "y_relu = relu(z)\n",
        "y_sigmoid = sigmoid(z)\n",
        "y_relu, y_sigmoid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e764019",
      "metadata": {
        "id": "8e764019"
      },
      "source": [
        "## 4) Autograd and gradients\n",
        "\n",
        "PyTorch uses **automatic differentiation** to compute gradients\n",
        "using the **chain rule** (backpropagation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "50f1aab4",
      "metadata": {
        "id": "50f1aab4",
        "outputId": "907eb1f4-1671-4a72-e9a0-b9a3995f9491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.890000104904175\n",
            "grad w: tensor([-3.4000, -6.8000,  3.4000])\n",
            "grad b: tensor(-3.4000)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, -1.0], requires_grad=True)\n",
        "w = torch.tensor([0.5, -0.3, 0.8], requires_grad=True)\n",
        "b = torch.tensor(0.2, requires_grad=True)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "loss = (z - 1.0) ** 2\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"loss:\", loss.item())\n",
        "print(\"grad w:\", w.grad)\n",
        "print(\"grad b:\", b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2c78a9",
      "metadata": {
        "id": "fe2c78a9"
      },
      "source": [
        "### ðŸ” Conceptual question\n",
        "\n",
        "- If `b.grad > 0`, should `b` increase or decrease after a gradient descent step?\n",
        "Explain **why** in one sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5bdee3e",
      "metadata": {
        "id": "b5bdee3e"
      },
      "source": [
        "## 5) Toy classification dataset\n",
        "\n",
        "We create a **linearly separable** dataset.\n",
        "\n",
        "Label rule:\n",
        "- class = 1 if `xâ‚ + xâ‚‚ + xâ‚ƒ > 0`\n",
        "- else class = 0\n",
        "\n",
        "This mimics a very simple classification problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "15c8bc6a",
      "metadata": {
        "id": "15c8bc6a"
      },
      "outputs": [],
      "source": [
        "# TODO: generate a dataset of size N=500 with 3 features\n",
        "X = torch.randn(500, 3)\n",
        "y = torch.randn(500, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(500):\n",
        "  if X[i, 0] + X[i, 1] + X[i, 2] > 0 :\n",
        "    y[i] = 1\n",
        "  else :\n",
        "    y[i] = 0"
      ],
      "metadata": {
        "id": "32bnwrMTDir1"
      },
      "id": "32bnwrMTDir1",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: split into train (80%) and validation (20%)\n",
        "\n",
        "X_train, X_val = X[:400], X[400:]\n",
        "y_train, y_val = y[:400], y[400:]\n"
      ],
      "metadata": {
        "id": "A5OfhLUMEIvi"
      },
      "id": "A5OfhLUMEIvi",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "cgteucc8EfIV",
        "outputId": "6a4d3df6-2580-4eee-a204-5dfd3eed363e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cgteucc8EfIV",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([400, 3]),\n",
              " torch.Size([200, 3]),\n",
              " torch.Size([400, 1]),\n",
              " torch.Size([200, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c16fc2",
      "metadata": {
        "id": "79c16fc2"
      },
      "source": [
        "## 6) Model definition\n",
        "\n",
        "We define a small **MLP** (fully-connected network):\n",
        "\n",
        "`3 â†’ 16 â†’ 8 â†’ 1`\n",
        "\n",
        "Activation: ReLU  \n",
        "Output: raw logits (no sigmoid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d7b69f8d",
      "metadata": {
        "id": "d7b69f8d"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(3, 16),       # TODO: Linear 3 â†’ 16\n",
        "            nn.ReLU(),              # TODO: ReLU\n",
        "            nn.Linear(16, 8),       # TODO: Linear 16 â†’ 8\n",
        "            nn.ReLU(),              # TODO: ReLU\n",
        "            nn.Linear(8, 1),       # TODO: Linear 8 â†’ 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# TODO: create model and move it to the GPU\n",
        "model = MLP().to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c13b2d2",
      "metadata": {
        "id": "9c13b2d2"
      },
      "source": [
        "###  parameters\n",
        "\n",
        "1. Compute **by hand** the total number of parameters\n",
        "2. Verify your answer using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6168e4a5",
      "metadata": {
        "id": "6168e4a5",
        "outputId": "81639519-726b-405b-8ed2-08fd50e77714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# TODO: count parameters with PyTorch\n",
        "total_params = 3*16 + 16 + 16*8 + 8 + 8*1 + 1\n",
        "total_params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f204fb",
      "metadata": {
        "id": "19f204fb"
      },
      "source": [
        "## 7) Training loop\n",
        "\n",
        "You must complete the full training loop:\n",
        "- forward pass\n",
        "- loss computation\n",
        "- backward pass\n",
        "- optimizer step\n",
        "\n",
        "Loss: `BCEWithLogitsLoss`\n",
        "Optimizer: `SGD`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d80ad2c9",
      "metadata": {
        "id": "d80ad2c9",
        "outputId": "5ceb34fc-6cde-448c-d426-299d30548bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3720491220.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# We can safely turn off functools.wraps here because the inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maot_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompile_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrecompileContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 58\u001b[0;31m from .variables import (\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mFunctionalCallVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuiltin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnumVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprocess_automatic_dynamic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m )\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mside_effects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSideEffects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m from ..source import (\n\u001b[1;32m     96\u001b[0m     \u001b[0mAttrProxySource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/side_effects.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutogradFunctionContextVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_break_hints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/misc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNestedUserFunctionVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserFunctionVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0muser_defined\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_random_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_standard_setattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserDefinedObjectVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fully_shard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_fsdp_param_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0m_fsdp_param_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/distributed/fsdp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mUnshardHandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m from .fully_sharded_data_parallel import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mBackwardPrefetch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mCPUOffload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_annotate_modules_for_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m from torch.distributed.fsdp._init_utils import (\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0m_check_orig_params_flattened\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0m_init_buffer_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/distributed/fsdp/_init_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_order_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexec_order_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traversal_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraversal_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_sharded_data_parallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsdp_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_cache_bytecode\u001b[0;34m(self, source_path, bytecode_path, data)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, path, data, _mode)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_split\u001b[0;34m(path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: move data to device\n",
        "X_train_d = X_train.to(device)\n",
        "y_train_d = y_train.to(device)\n",
        "X_val_d = X_test.to(device)\n",
        "y_val_d = y_test.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # TODO: forward\n",
        "    logits = model.forward(X_train_d)\n",
        "\n",
        "    # TODO: loss\n",
        "    loss = criterion(logits, y_train_d)\n",
        "\n",
        "    # TODO: backward\n",
        "    loss.backward()\n",
        "\n",
        "    # TODO: update\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch\", epoch, \"| loss =\", float(loss))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c894744",
      "metadata": {
        "id": "5c894744"
      },
      "source": [
        "## 8) Evaluation\n",
        "\n",
        "1. Apply `sigmoid` to the logits\n",
        "2. Convert probabilities to predictions\n",
        "3. Compute **accuracy** on the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10b706c",
      "metadata": {
        "id": "b10b706c"
      },
      "outputs": [],
      "source": [
        "# TODO: evaluation\n",
        "# with torch.no_grad():\n",
        "#     logits = ...\n",
        "#     probs = ...\n",
        "#     preds = ...\n",
        "\n",
        "# accuracy = ...\n",
        "# accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9698541c",
      "metadata": {
        "id": "9698541c"
      },
      "source": [
        "## 9) Reflection questions (answer inside the markdown)\n",
        "\n",
        "1. Why do we **not** apply sigmoid inside the model?\n",
        "2. What would happen if we removed all ReLU activations?\n",
        "3. How does this toy problem relate to image classification?\n",
        "\n",
        "Write short answers (2â€“3 lines each).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9f2ed3",
      "metadata": {
        "id": "be9f2ed3"
      },
      "source": [
        "## 10) Bridge to Computer Vision\n",
        "\n",
        "So far:\n",
        "- inputs = vectors of size 3\n",
        "- layers = fully-connected\n",
        "\n",
        "Next session:\n",
        "- inputs = images `(B, C, H, W)`\n",
        "- layers = convolutions\n",
        "- same training logic\n",
        "\n",
        "ðŸ‘‰ **Architecture changes, learning principles stay the same.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f479aad6",
      "metadata": {
        "id": "f479aad6"
      },
      "source": [
        "## Part II â€” Training on MNIST\n",
        "\n",
        "Check the next notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}